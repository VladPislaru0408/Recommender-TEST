{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality-Focused Influencer Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALL data including group filters\n",
    "DATA_PATH = '/home/vlad/Work/fj-recommendations/Mydata/data/'\n",
    "\n",
    "# Core data\n",
    "campaigns = pd.read_csv(f'{DATA_PATH}Campaigns.csv')\n",
    "briefs = pd.read_csv(f'{DATA_PATH}Briefs.csv')\n",
    "influencers = pd.read_csv(f'{DATA_PATH}Influencers.csv')\n",
    "interactions = pd.read_csv(f'{DATA_PATH}Interactions.csv')\n",
    "\n",
    "# Group filter data\n",
    "groups = pd.read_csv(f'{DATA_PATH}Groups.csv')\n",
    "user_info = pd.read_csv(f'{DATA_PATH}User_Info.csv')\n",
    "group_locations = pd.read_csv(f'{DATA_PATH}Group_Locations.csv')\n",
    "group_categories = pd.read_csv(f'{DATA_PATH}Group_Categories.csv')\n",
    "group_creator_prefs = pd.read_csv(f'{DATA_PATH}Group_Creator_Preferences.csv')\n",
    "creator_prefs = pd.read_csv(f'{DATA_PATH}Creator_Preferences.csv')\n",
    "user_categories = pd.read_csv(f'{DATA_PATH}User_Categories.csv')\n",
    "\n",
    "print(f\"Loaded: {len(campaigns)} campaigns, {len(influencers)} influencers, {len(interactions)} interactions\")\n",
    "print(f\"Groups: {len(groups)}, User_Info: {len(user_info)}, User_Categories: {len(user_categories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Quality Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality score for each influencer\n",
    "def calculate_quality_score(df):\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Engagement (40%)\n",
    "    eng_cap = result['engagement'].quantile(0.99)\n",
    "    result['eng_norm'] = (result['engagement'].clip(0, eng_cap) / eng_cap).fillna(0)\n",
    "    \n",
    "    # Followers (25%) - log scale\n",
    "    result['foll_log'] = np.log1p(result['followers'].fillna(0))\n",
    "    foll_max = result['foll_log'].quantile(0.99)\n",
    "    result['foll_norm'] = (result['foll_log'] / foll_max).clip(0, 1)\n",
    "    \n",
    "    # Avg likes (20%) - log scale\n",
    "    result['likes_log'] = np.log1p(result['avg_likes'].fillna(0))\n",
    "    likes_max = result['likes_log'].quantile(0.99)\n",
    "    result['likes_norm'] = (result['likes_log'] / likes_max).clip(0, 1)\n",
    "    \n",
    "    # Avg comments (15%) - log scale\n",
    "    result['comments_log'] = np.log1p(result['avg_comments'].fillna(0))\n",
    "    comments_max = result['comments_log'].quantile(0.99)\n",
    "    result['comments_norm'] = (result['comments_log'] / comments_max).clip(0, 1)\n",
    "    \n",
    "    # Weighted score (0-100)\n",
    "    result['quality_score'] = (\n",
    "        result['eng_norm'] * 40 +\n",
    "        result['foll_norm'] * 25 +\n",
    "        result['likes_norm'] * 20 +\n",
    "        result['comments_norm'] * 15\n",
    "    )\n",
    "    return result\n",
    "\n",
    "influencers_scored = calculate_quality_score(influencers)\n",
    "print(\"Quality score calculated\")\n",
    "print(f\"Influencers with user_id: {influencers_scored['user_id'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define group filter function\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_eligible_influencers(campaign_id):\n",
    "    \"\"\"\n",
    "    Get influencers that pass all group filters for a campaign.\n",
    "    Returns list of eligible influencer IDs.\n",
    "    \"\"\"\n",
    "    camp_groups = groups[groups['campaign_id'] == campaign_id]\n",
    "    \n",
    "    if len(camp_groups) == 0:\n",
    "        return influencers_scored['id'].tolist()\n",
    "    \n",
    "    eligible_ids = set()\n",
    "    \n",
    "    for _, group in camp_groups.iterrows():\n",
    "        group_id = group['id']\n",
    "        candidates = influencers_scored[influencers_scored['user_id'].notna()].copy()\n",
    "        \n",
    "        # 1. TIER FILTER\n",
    "        if pd.notna(group['creators_tiers']):\n",
    "            try:\n",
    "                tiers = json.loads(group['creators_tiers'])\n",
    "                candidates = candidates[candidates['tier_level'].isin(tiers)]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 2. COUNTRY FILTER\n",
    "        if pd.notna(group['country_id']):\n",
    "            country_users = set(user_info[user_info['country_id'] == group['country_id']]['user_id'])\n",
    "            candidates = candidates[candidates['user_id'].isin(country_users)]\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 3. LOCATION FILTER - Skip if region is NaN\n",
    "        grp_locations = group_locations[group_locations['group_id'] == group_id]\n",
    "        if len(grp_locations) > 0:\n",
    "            valid_locations = grp_locations[grp_locations['region_id'].notna()]\n",
    "            if len(valid_locations) > 0:\n",
    "                location_users = set()\n",
    "                for _, loc in valid_locations.iterrows():\n",
    "                    if pd.isna(loc['city_id']):\n",
    "                        region_users = user_info[user_info['region_id'] == loc['region_id']]['user_id']\n",
    "                    else:\n",
    "                        region_users = user_info[\n",
    "                            (user_info['region_id'] == loc['region_id']) & \n",
    "                            (user_info['city_id'] == loc['city_id'])\n",
    "                        ]['user_id']\n",
    "                    location_users.update(region_users)\n",
    "                candidates = candidates[candidates['user_id'].isin(location_users)]\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 4. CATEGORY FILTER\n",
    "        grp_cats = group_categories[group_categories['group_id'] == group_id]['category_id'].tolist()\n",
    "        if len(grp_cats) > 0:\n",
    "            cat_users = set(user_categories[user_categories['category_id'].isin(grp_cats)]['user_id'])\n",
    "            candidates = candidates[candidates['user_id'].isin(cat_users)]\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 5. GENDER FILTER\n",
    "        grp_prefs = group_creator_prefs[group_creator_prefs['group_id'] == group_id]\n",
    "        gender_pref_ids = grp_prefs['creator_preference_id'].tolist()\n",
    "        gender_prefs = creator_prefs[\n",
    "            (creator_prefs['id'].isin(gender_pref_ids)) & \n",
    "            (creator_prefs['creator_preference_type_id'] == 2)\n",
    "        ]['name'].tolist()\n",
    "        \n",
    "        if len(gender_prefs) > 0:\n",
    "            gender_map = {'Women': 2, 'Men': 1, 'Other': 0}\n",
    "            gender_values = [gender_map.get(g) for g in gender_prefs if g in gender_map]\n",
    "            if gender_values:\n",
    "                gender_users = set(user_info[user_info['gender'].isin(gender_values)]['user_id'])\n",
    "                candidates = candidates[candidates['user_id'].isin(gender_users)]\n",
    "        \n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 6. AGE FILTER\n",
    "        age_pref_ids = grp_prefs['creator_preference_id'].tolist()\n",
    "        age_prefs = creator_prefs[\n",
    "            (creator_prefs['id'].isin(age_pref_ids)) & \n",
    "            (creator_prefs['creator_preference_type_id'] == 1)\n",
    "        ]['name'].tolist()\n",
    "        \n",
    "        if len(age_prefs) > 0:\n",
    "            today = datetime.now()\n",
    "            age_users = set()\n",
    "            user_info_with_age = user_info[user_info['birthday'].notna()].copy()\n",
    "            user_info_with_age['birthday'] = pd.to_datetime(user_info_with_age['birthday'], errors='coerce')\n",
    "            user_info_with_age['age'] = (today - user_info_with_age['birthday']).dt.days // 365\n",
    "            \n",
    "            for age_range in age_prefs:\n",
    "                if age_range == '55+':\n",
    "                    matching = user_info_with_age[user_info_with_age['age'] >= 55]['user_id']\n",
    "                elif '-' in age_range:\n",
    "                    min_age, max_age = map(int, age_range.split('-'))\n",
    "                    matching = user_info_with_age[\n",
    "                        (user_info_with_age['age'] >= min_age) & \n",
    "                        (user_info_with_age['age'] <= max_age)\n",
    "                    ]['user_id']\n",
    "                else:\n",
    "                    continue\n",
    "                age_users.update(matching)\n",
    "            \n",
    "            if age_users:\n",
    "                candidates = candidates[candidates['user_id'].isin(age_users)]\n",
    "        \n",
    "        eligible_ids.update(candidates['id'].tolist())\n",
    "    \n",
    "    return list(eligible_ids)\n",
    "\n",
    "# Test it\n",
    "eligible = get_eligible_influencers(2817)\n",
    "print(f\"get_eligible_influencers defined. Test campaign 2817: {len(eligible)} eligible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accepted column and merge with influencers\n",
    "interactions['accepted'] = (interactions['status'] == 2).astype(int)\n",
    "\n",
    "df = interactions.merge(\n",
    "    influencers_scored[['id', 'network_id', 'followers', 'follows', 'engagement',\n",
    "                         'avg_likes', 'avg_comments', 'posts', 'reach', 'impressions',\n",
    "                         'tier_level', 'quality_score']],\n",
    "    left_on='creator_id', right_on='id', how='inner'\n",
    ")\n",
    "print(f\"Interactions with influencers: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge campaign data\n",
    "camp_cols = campaigns[['id', 'type_id', 'description', 'private', 'pre_approve']].copy()\n",
    "camp_cols = camp_cols.rename(columns={'id': 'camp_id', 'description': 'campaign_description'})\n",
    "df = df.merge(camp_cols, left_on='campaign_id', right_on='camp_id', how='left')\n",
    "\n",
    "# Merge brief data\n",
    "brief_cols = briefs[['id', 'description']].copy()\n",
    "brief_cols = brief_cols.rename(columns={'id': 'b_id', 'description': 'brief_description'})\n",
    "df = df.merge(brief_cols, left_on='brief_id', right_on='b_id', how='left')\n",
    "\n",
    "print(f\"After merging: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "numeric_cols = ['followers', 'follows', 'engagement', 'avg_likes', 'avg_comments',\n",
    "                'posts', 'reach', 'impressions', 'quality_score']\n",
    "cat_cols = ['network_id', 'type_id', 'private', 'pre_approve', 'tier_level']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(-1).astype(int)\n",
    "print(\"Missing values filled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF on unique briefs (memory efficient)\n",
    "df['brief_description'] = df['brief_description'].fillna('')\n",
    "df['campaign_description'] = df['campaign_description'].fillna('')\n",
    "\n",
    "unique_briefs = df[['brief_id', 'campaign_description', 'brief_description']].drop_duplicates('brief_id')\n",
    "unique_briefs['text'] = unique_briefs['campaign_description'] + ' ' + unique_briefs['brief_description']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(unique_briefs['text'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(50)])\n",
    "tfidf_df['brief_id'] = unique_briefs['brief_id'].values\n",
    "\n",
    "df = df.merge(tfidf_df, on='brief_id', how='left')\n",
    "for i in range(50):\n",
    "    df[f'tfidf_{i}'] = df[f'tfidf_{i}'].fillna(0)\n",
    "print(\"TF-IDF features added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical stats\n",
    "creator_stats = interactions.groupby('creator_id')['accepted'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "creator_stats.columns = ['creator_id', 'total_accepted', 'total_interactions', 'acceptance_rate']\n",
    "\n",
    "campaign_stats = interactions.groupby('campaign_id')['accepted'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "campaign_stats.columns = ['campaign_id', 'camp_accepted', 'camp_interactions', 'camp_acceptance_rate']\n",
    "\n",
    "df = df.merge(creator_stats, on='creator_id', how='left')\n",
    "df = df.merge(campaign_stats, on='campaign_id', how='left')\n",
    "\n",
    "for col in ['acceptance_rate', 'total_accepted', 'total_interactions', 'camp_acceptance_rate', 'camp_accepted', 'camp_interactions']:\n",
    "    df[col] = df[col].fillna(0)\n",
    "print(f\"Dataset ready: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and train\n",
    "tfidf_feats = [f'tfidf_{i}' for i in range(50)]\n",
    "hist_feats = ['acceptance_rate', 'total_accepted', 'total_interactions',\n",
    "              'camp_acceptance_rate', 'camp_accepted', 'camp_interactions']\n",
    "\n",
    "all_features = numeric_cols + cat_cols + tfidf_feats + hist_feats\n",
    "all_features = [f for f in all_features if f in df.columns]\n",
    "\n",
    "X = df[all_features].fillna(0)\n",
    "y = df['accepted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "params = {'objective': 'binary', 'metric': 'auc', 'verbosity': -1,\n",
    "          'num_leaves': 31, 'learning_rate': 0.05, 'is_unbalance': True}\n",
    "\n",
    "model = lgb.train(params, train_data, 300, valid_sets=[test_data],\n",
    "                  callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nROC-AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Show network mapping\n",
    "print(\"\\n=== NETWORK MAPPING ===\")\n",
    "print(\"Network 1: Instagram\")\n",
    "print(\"Network 8: TikTok\")\n",
    "print(\"Network 9: Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Campaign-Aware Recommendation Functions\n",
    "\n",
    "Key insight: Different campaigns target different networks (Instagram vs TikTok) and have zero overlap in successful influencers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_campaign(campaign_id, brief_id, top_n=10,\n",
    "                           min_followers=1000, min_engagement=1.0,\n",
    "                           quality_weight=0.7, acceptance_weight=0.3):\n",
    "    \"\"\"\n",
    "    Campaign-aware recommendations that:\n",
    "    1. Filter by campaign's network (Instagram/TikTok)\n",
    "    2. Use text similarity between influencer bio and campaign description\n",
    "    3. Weight quality + acceptance probability\n",
    "    \"\"\"\n",
    "    camp_info = campaigns[campaigns['id'] == campaign_id].iloc[0]\n",
    "    brief_info = briefs[briefs['id'] == brief_id].iloc[0]\n",
    "    \n",
    "    campaign_network = camp_info['network_id']\n",
    "    campaign_text = str(camp_info.get('description', '')) + ' ' + str(brief_info.get('description', ''))\n",
    "    \n",
    "    print(f\"Campaign: {camp_info['name']}\")\n",
    "    print(f\"Network: {campaign_network} ({'Instagram' if campaign_network == 1 else 'TikTok' if campaign_network == 8 else 'Other'})\") \n",
    "    \n",
    "    # Start with quality influencers\n",
    "    pred_df = influencers_scored[\n",
    "        (influencers_scored['followers'] >= min_followers) &\n",
    "        (influencers_scored['engagement'] >= min_engagement)\n",
    "    ].copy()\n",
    "    \n",
    "    # IMPORTANT: Filter by campaign network!\n",
    "    pred_df = pred_df[pred_df['network_id'] == campaign_network]\n",
    "    print(f\"Influencers on this network: {len(pred_df)}\")\n",
    "    \n",
    "    # Exclude already interacted\n",
    "    already = interactions[interactions['campaign_id'] == campaign_id]['creator_id'].unique()\n",
    "    pred_df = pred_df[~pred_df['id'].isin(already)]\n",
    "    print(f\"After excluding already contacted: {len(pred_df)}\")\n",
    "    \n",
    "    if len(pred_df) == 0:\n",
    "        print(\"No influencers available!\")\n",
    "        return None\n",
    "    \n",
    "    # Add campaign features for model\n",
    "    pred_df['campaign_id'] = campaign_id\n",
    "    pred_df['type_id'] = camp_info.get('type_id', -1)\n",
    "    pred_df['private'] = camp_info.get('private', 0)\n",
    "    pred_df['pre_approve'] = camp_info.get('pre_approve', 0)\n",
    "    \n",
    "    # TF-IDF features from campaign text\n",
    "    tfidf_arr = tfidf.transform([campaign_text]).toarray()[0]\n",
    "    for i in range(50):\n",
    "        pred_df[f'tfidf_{i}'] = tfidf_arr[i]\n",
    "    \n",
    "    # Calculate text similarity between influencer bio and campaign\n",
    "    pred_df['biography'] = pred_df['biography'].fillna('')\n",
    "    bio_tfidf = tfidf.transform(pred_df['biography'].tolist())\n",
    "    campaign_tfidf = tfidf.transform([campaign_text])\n",
    "    \n",
    "    # Cosine similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarities = cosine_similarity(bio_tfidf, campaign_tfidf).flatten()\n",
    "    pred_df['bio_similarity'] = similarities\n",
    "    \n",
    "    # Add historical features\n",
    "    pred_df = pred_df.merge(creator_stats, left_on='id', right_on='creator_id', how='left')\n",
    "    pred_df = pred_df.merge(campaign_stats, on='campaign_id', how='left')\n",
    "    \n",
    "    # Fill missing features\n",
    "    for col in all_features:\n",
    "        if col not in pred_df.columns:\n",
    "            pred_df[col] = 0\n",
    "        pred_df[col] = pred_df[col].fillna(0)\n",
    "    \n",
    "    # Predict acceptance probability\n",
    "    pred_df['acceptance_prob'] = model.predict(pred_df[all_features])\n",
    "    \n",
    "    # Normalize scores\n",
    "    pred_df['quality_norm'] = pred_df['quality_score'] / pred_df['quality_score'].max()\n",
    "    pred_df['similarity_norm'] = pred_df['bio_similarity'] / (pred_df['bio_similarity'].max() + 0.001)\n",
    "    \n",
    "    # Combined score: quality + acceptance + bio similarity\n",
    "    pred_df['final_score'] = (\n",
    "        pred_df['quality_norm'] * quality_weight * 0.6 +\n",
    "        pred_df['acceptance_prob'] * acceptance_weight +\n",
    "        pred_df['similarity_norm'] * quality_weight * 0.4  # Bio match is part of quality\n",
    "    )\n",
    "    \n",
    "    result = pred_df.nlargest(top_n, 'final_score')[\n",
    "        ['id', 'account', 'name', 'followers', 'engagement', 'avg_likes', \n",
    "         'quality_score', 'bio_similarity', 'acceptance_prob', 'final_score']\n",
    "    ].copy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old function - we'll use the new campaign-aware one\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper Evaluation: Train on Old Campaigns, Test on New\n",
    "\n",
    "We'll:\n",
    "1. Train on campaigns before April 2024\n",
    "2. Test on campaigns after April 2024\n",
    "3. For each test campaign, recommend top N influencers\n",
    "4. Measure how many of our recommendations match the actual accepted influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split campaigns by date\n",
    "campaigns['created_at'] = pd.to_datetime(campaigns['created_at'])\n",
    "SPLIT_DATE = '2024-04-01'\n",
    "\n",
    "train_campaigns = campaigns[campaigns['created_at'] < SPLIT_DATE]['id'].tolist()\n",
    "test_campaigns = campaigns[campaigns['created_at'] >= SPLIT_DATE]['id'].tolist()\n",
    "\n",
    "# Get interactions for train/test\n",
    "train_interactions = interactions[interactions['campaign_id'].isin(train_campaigns)].copy()\n",
    "test_interactions = interactions[interactions['campaign_id'].isin(test_campaigns)].copy()\n",
    "\n",
    "print(f\"Training campaigns: {len(train_campaigns)}\")\n",
    "print(f\"Test campaigns: {len(test_campaigns)}\")\n",
    "print(f\"Training interactions: {len(train_interactions)}\")\n",
    "print(f\"Test interactions: {len(test_interactions)}\")\n",
    "\n",
    "# Filter test to campaigns with at least 5 accepted\n",
    "test_accepted = test_interactions[test_interactions['accepted'] == 1].groupby('campaign_id').size()\n",
    "test_camps_with_accepted = test_accepted[test_accepted >= 5].index.tolist()\n",
    "print(f\"\\nTest campaigns with 5+ accepted influencers: {len(test_camps_with_accepted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training data using ONLY training campaigns\n",
    "# Historical stats from training data only\n",
    "train_creator_stats = train_interactions.groupby('creator_id')['accepted'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "train_creator_stats.columns = ['creator_id', 'total_accepted', 'total_interactions', 'acceptance_rate']\n",
    "\n",
    "train_campaign_stats = train_interactions.groupby('campaign_id')['accepted'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "train_campaign_stats.columns = ['campaign_id', 'camp_accepted', 'camp_interactions', 'camp_acceptance_rate']\n",
    "\n",
    "# Build training dataset - use influencers_scored instead of quality_influencers\n",
    "train_df = train_interactions.merge(\n",
    "    influencers_scored[['id', 'network_id', 'followers', 'follows', 'engagement',\n",
    "                         'avg_likes', 'avg_comments', 'posts', 'reach', 'impressions',\n",
    "                         'tier_level', 'quality_score', 'biography']],\n",
    "    left_on='creator_id', right_on='id', how='inner'\n",
    ")\n",
    "\n",
    "# Merge campaign data\n",
    "camp_cols = campaigns[['id', 'type_id', 'description', 'private', 'pre_approve', 'network_id']].copy()\n",
    "camp_cols = camp_cols.rename(columns={'id': 'camp_id', 'description': 'campaign_description', 'network_id': 'camp_network'})\n",
    "train_df = train_df.merge(camp_cols, left_on='campaign_id', right_on='camp_id', how='left')\n",
    "\n",
    "# Merge brief data\n",
    "brief_cols = briefs[['id', 'description']].copy()\n",
    "brief_cols = brief_cols.rename(columns={'id': 'b_id', 'description': 'brief_description'})\n",
    "train_df = train_df.merge(brief_cols, left_on='brief_id', right_on='b_id', how='left')\n",
    "\n",
    "print(f\"Training data: {len(train_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for training\n",
    "train_df['brief_description'] = train_df['brief_description'].fillna('')\n",
    "train_df['campaign_description'] = train_df['campaign_description'].fillna('')\n",
    "\n",
    "# Fill numeric/categorical\n",
    "for col in numeric_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(0)\n",
    "for col in cat_cols:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].fillna(-1).astype(int)\n",
    "\n",
    "# TF-IDF on training briefs only\n",
    "train_unique_briefs = train_df[['brief_id', 'campaign_description', 'brief_description']].drop_duplicates('brief_id')\n",
    "train_unique_briefs['text'] = train_unique_briefs['campaign_description'] + ' ' + train_unique_briefs['brief_description']\n",
    "\n",
    "train_tfidf = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "train_tfidf_matrix = train_tfidf.fit_transform(train_unique_briefs['text'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(train_tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(50)])\n",
    "tfidf_df['brief_id'] = train_unique_briefs['brief_id'].values\n",
    "\n",
    "train_df = train_df.merge(tfidf_df, on='brief_id', how='left')\n",
    "for i in range(50):\n",
    "    train_df[f'tfidf_{i}'] = train_df[f'tfidf_{i}'].fillna(0)\n",
    "\n",
    "# Add historical stats\n",
    "train_df = train_df.merge(train_creator_stats, on='creator_id', how='left')\n",
    "train_df = train_df.merge(train_campaign_stats, on='campaign_id', how='left')\n",
    "for col in ['acceptance_rate', 'total_accepted', 'total_interactions', 'camp_acceptance_rate', 'camp_accepted', 'camp_interactions']:\n",
    "    train_df[col] = train_df[col].fillna(0)\n",
    "\n",
    "print(f\"Training features prepared: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on training data only\n",
    "tfidf_feats = [f'tfidf_{i}' for i in range(50)]\n",
    "hist_feats = ['acceptance_rate', 'total_accepted', 'total_interactions',\n",
    "              'camp_acceptance_rate', 'camp_accepted', 'camp_interactions']\n",
    "\n",
    "train_features = numeric_cols + cat_cols + tfidf_feats + hist_feats\n",
    "train_features = [f for f in train_features if f in train_df.columns]\n",
    "\n",
    "X_train = train_df[train_features].fillna(0)\n",
    "y_train = train_df['accepted']\n",
    "\n",
    "print(f\"Training on {len(X_train)} samples with {len(train_features)} features\")\n",
    "\n",
    "# Train\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "params = {'objective': 'binary', 'metric': 'auc', 'verbosity': -1,\n",
    "          'num_leaves': 31, 'learning_rate': 0.05, 'is_unbalance': True}\n",
    "\n",
    "eval_model = lgb.train(params, train_data, 200)\n",
    "print(\"Model trained on historical data only!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: History-based recommendations with recency weighting\n",
    "# This approach achieves ~17-26% recall (vs 3% for the LightGBM model)\n",
    "\n",
    "# Calculate recency-weighted acceptance scores from training data\n",
    "train_interactions['created_at'] = pd.to_datetime(train_interactions['created_at'])\n",
    "max_train_date = train_interactions['created_at'].max()\n",
    "\n",
    "# Recency weight: more recent acceptances count more\n",
    "train_interactions['days_ago'] = (max_train_date - train_interactions['created_at']).dt.days\n",
    "train_interactions['recency_weight'] = np.exp(-train_interactions['days_ago'] / 180)  # 6-month half-life\n",
    "\n",
    "# Calculate recency-weighted acceptance score per creator\n",
    "train_accepted = train_interactions[train_interactions['accepted'] == 1].copy()\n",
    "recency_scores = train_accepted.groupby('creator_id')['recency_weight'].sum().reset_index()\n",
    "recency_scores.columns = ['creator_id', 'recency_score']\n",
    "\n",
    "# Also keep regular acceptance count\n",
    "creator_history = train_interactions.groupby('creator_id').agg({\n",
    "    'accepted': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "creator_history.columns = ['creator_id', 'times_accepted', 'times_applied', 'acceptance_rate']\n",
    "creator_history = creator_history.merge(recency_scores, on='creator_id', how='left')\n",
    "creator_history['recency_score'] = creator_history['recency_score'].fillna(0)\n",
    "\n",
    "print(f\"Creator history calculated: {len(creator_history)} creators\")\n",
    "print(f\"Creators with 1+ acceptance: {(creator_history['times_accepted'] > 0).sum()}\")\n",
    "\n",
    "def get_recommendations_history(campaign_id, top_n=50):\n",
    "    \"\"\"\n",
    "    History-based recommendations using recency-weighted acceptance count.\n",
    "    Key insight: Past acceptance is the strongest predictor of future acceptance.\n",
    "    \"\"\"\n",
    "    camp = campaigns[campaigns['id'] == campaign_id].iloc[0]\n",
    "    network = camp['network_id']\n",
    "    \n",
    "    # Get eligible influencers from group filters\n",
    "    eligible = get_eligible_influencers(campaign_id)\n",
    "    \n",
    "    # Filter to eligible + correct network\n",
    "    pool = influencers_scored[\n",
    "        (influencers_scored['id'].isin(eligible)) &\n",
    "        (influencers_scored['network_id'] == network)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(pool) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Add history\n",
    "    pool = pool.merge(creator_history, left_on='id', right_on='creator_id', how='left')\n",
    "    pool['times_accepted'] = pool['times_accepted'].fillna(0)\n",
    "    pool['recency_score'] = pool['recency_score'].fillna(0)\n",
    "    \n",
    "    # Score by recency-weighted acceptance count\n",
    "    pool['score'] = pool['recency_score']\n",
    "    \n",
    "    return pool.nlargest(top_n, 'score')['id'].tolist()\n",
    "\n",
    "print(\"History-based recommendation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate HISTORY-BASED recommendations on test campaigns\n",
    "results = []\n",
    "\n",
    "# Sort test campaigns by date (newest first) and take first 100\n",
    "test_camps_sorted = campaigns[campaigns['id'].isin(test_camps_with_accepted)].sort_values('created_at', ascending=False)\n",
    "newest_test_camps = test_camps_sorted['id'].head(100).tolist()\n",
    "\n",
    "print(f\"Evaluating HISTORY-BASED recommendations on 100 newest campaigns\")\n",
    "print(f\"Date range: {test_camps_sorted['created_at'].iloc[99]} to {test_camps_sorted['created_at'].iloc[0]}\")\n",
    "\n",
    "for i, camp_id in enumerate(newest_test_camps):\n",
    "    if (i + 1) % 25 == 0:\n",
    "        print(f\"  Processing campaign {i+1}/100...\")\n",
    "    \n",
    "    # Get actual accepted influencers\n",
    "    actual_accepted = test_interactions[\n",
    "        (test_interactions['campaign_id'] == camp_id) & \n",
    "        (test_interactions['accepted'] == 1)\n",
    "    ]['creator_id'].unique()\n",
    "    \n",
    "    if len(actual_accepted) < 5:\n",
    "        continue\n",
    "    \n",
    "    # Get recommendations using history-based method\n",
    "    for top_n in [50, 100, 200]:\n",
    "        recommended = get_recommendations_history(camp_id, top_n=top_n)\n",
    "        if recommended is None:\n",
    "            continue\n",
    "        \n",
    "        # Calculate metrics\n",
    "        recommended_set = set(recommended)\n",
    "        actual_set = set(actual_accepted)\n",
    "        \n",
    "        hits = len(recommended_set & actual_set)\n",
    "        precision = hits / len(recommended_set) if len(recommended_set) > 0 else 0\n",
    "        recall = hits / len(actual_set) if len(actual_set) > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'campaign_id': camp_id,\n",
    "            'top_n': top_n,\n",
    "            'actual_accepted': len(actual_set),\n",
    "            'recommended': len(recommended_set),\n",
    "            'hits': hits,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nEvaluated {results_df['campaign_id'].nunique()} campaigns\")\n",
    "\n",
    "# Show summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EVALUATION SUMMARY - HISTORY-BASED RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "summary = results_df.groupby('top_n').agg({\n",
    "    'hits': 'sum',\n",
    "    'actual_accepted': 'sum',\n",
    "    'recommended': 'sum',\n",
    "}).reset_index()\n",
    "summary['precision'] = summary['hits'] / summary['recommended']\n",
    "summary['recall'] = summary['hits'] / summary['actual_accepted']\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== INTERPRETATION ===\")\n",
    "for _, row in summary.iterrows():\n",
    "    print(f\"Top {int(row['top_n'])}: Found {row['recall']*100:.1f}% of accepted influencers ({int(row['hits'])} hits)\")\n",
    "\n",
    "print(\"\\n=== KEY INSIGHT ===\")\n",
    "print(\"History-based recommendations (using past acceptance count) significantly\")\n",
    "print(\"outperform ML models because:\")\n",
    "print(\"1. 86% of test-accepted influencers have NO training history (cold-start)\")\n",
    "print(\"2. For the 14% with history, past acceptance is the strongest predictor\")\n",
    "print(\"3. Profile features (followers, engagement) have weak predictive power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis & Prioritized Model Training\n",
    "\n",
    "Based on data analysis, here's what actually predicts acceptance:\n",
    "\n",
    "| Feature | Correlation | Insight |\n",
    "|---------|-------------|---------|\n",
    "| **acceptance_rate** | +0.77 | BY FAR the strongest predictor |\n",
    "| **times_accepted** | +0.23 | Past success predicts future |\n",
    "| **impressions** | +0.04 | Weak positive |\n",
    "| **times_applied** | -0.16 | Negative! Spammy applicants rejected |\n",
    "| **followers** | -0.03 | Slightly negative (surprising!) |\n",
    "| **engagement** | ~0 | No correlation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM with PRIORITIZED features (history first, then reach, then profile)\n",
    "\n",
    "# Define prioritized features based on correlation analysis\n",
    "prioritized_features = [\n",
    "    # TIER 1: History (strongest predictors - correlation 0.23 to 0.77)\n",
    "    'acceptance_rate',      # 0.77 correlation - THE key feature  \n",
    "    'total_accepted',       # 0.23 correlation - times_accepted renamed\n",
    "    'recency_score',        # recency-weighted acceptances\n",
    "    \n",
    "    # TIER 2: Activity signals  \n",
    "    'total_interactions',   # times_applied (negative correlation = spammy)\n",
    "    \n",
    "    # TIER 3: Reach metrics (weak positive - 0.02 to 0.04)\n",
    "    'impressions',\n",
    "    'reach',\n",
    "    \n",
    "    # TIER 4: Profile metrics (very weak - for cold start only)\n",
    "    'followers',\n",
    "    'avg_comments',\n",
    "    'avg_likes', \n",
    "    'engagement',\n",
    "    'posts',\n",
    "]\n",
    "\n",
    "# Build training data with these features\n",
    "train_df_priority = train_interactions.merge(\n",
    "    influencers_scored[['id', 'followers', 'engagement', 'avg_likes', \n",
    "                        'avg_comments', 'reach', 'impressions', 'posts']],\n",
    "    left_on='creator_id', right_on='id', how='inner'\n",
    ")\n",
    "\n",
    "# Add history features\n",
    "train_df_priority = train_df_priority.merge(\n",
    "    creator_history[['creator_id', 'times_accepted', 'times_applied', 'acceptance_rate', 'recency_score']], \n",
    "    on='creator_id', how='left'\n",
    ")\n",
    "\n",
    "# Rename to match our feature list\n",
    "train_df_priority = train_df_priority.rename(columns={\n",
    "    'times_accepted': 'total_accepted',\n",
    "    'times_applied': 'total_interactions'\n",
    "})\n",
    "\n",
    "# Fill missing values\n",
    "for col in prioritized_features:\n",
    "    if col in train_df_priority.columns:\n",
    "        train_df_priority[col] = train_df_priority[col].fillna(0)\n",
    "\n",
    "X_priority = train_df_priority[prioritized_features].fillna(0)\n",
    "y_priority = train_df_priority['accepted']\n",
    "\n",
    "print(f\"Training PRIORITIZED model on {len(X_priority)} samples\")\n",
    "print(f\"Features (in priority order): {prioritized_features}\")\n",
    "\n",
    "# Train LightGBM\n",
    "train_data_priority = lgb.Dataset(X_priority, label=y_priority)\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc', \n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'is_unbalance': True,\n",
    "}\n",
    "\n",
    "priority_model = lgb.train(params, train_data_priority, 200)\n",
    "\n",
    "# Show what the model learned\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL LEARNED FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 70)\n",
    "importance = dict(zip(prioritized_features, priority_model.feature_importance()))\n",
    "for feat, imp in sorted(importance.items(), key=lambda x: -x[1]):\n",
    "    bar = \"â–ˆ\" * (imp // 50)\n",
    "    print(f\"  {feat:20s}: {imp:5d} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate PRIORITIZED MODEL vs HISTORY-ONLY baseline\n",
    "\n",
    "def get_recommendations_priority_model(campaign_id, top_n=100):\n",
    "    \"\"\"Use the prioritized LightGBM model for recommendations.\"\"\"\n",
    "    camp = campaigns[campaigns['id'] == campaign_id].iloc[0]\n",
    "    network = camp['network_id']\n",
    "    \n",
    "    eligible = get_eligible_influencers(campaign_id)\n",
    "    pool = influencers_scored[\n",
    "        (influencers_scored['id'].isin(eligible)) &\n",
    "        (influencers_scored['network_id'] == network)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(pool) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Add history features\n",
    "    pool = pool.merge(creator_history, left_on='id', right_on='creator_id', how='left')\n",
    "    pool = pool.rename(columns={\n",
    "        'times_accepted': 'total_accepted',\n",
    "        'times_applied': 'total_interactions'\n",
    "    })\n",
    "    \n",
    "    # Fill missing\n",
    "    for col in prioritized_features:\n",
    "        if col not in pool.columns:\n",
    "            pool[col] = 0\n",
    "        pool[col] = pool[col].fillna(0)\n",
    "    \n",
    "    # Predict using prioritized model\n",
    "    pool['score'] = priority_model.predict(pool[prioritized_features])\n",
    "    \n",
    "    return pool.nlargest(top_n, 'score')['id'].tolist()\n",
    "\n",
    "# Run evaluation\n",
    "print(\"=\" * 70)\n",
    "print(\"EVALUATION: PRIORITIZED MODEL vs HISTORY BASELINE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_model = []\n",
    "results_history = []\n",
    "\n",
    "for camp_id in newest_test_camps:\n",
    "    actual_accepted = test_interactions[\n",
    "        (test_interactions['campaign_id'] == camp_id) & \n",
    "        (test_interactions['accepted'] == 1)\n",
    "    ]['creator_id'].unique()\n",
    "    \n",
    "    if len(actual_accepted) < 5:\n",
    "        continue\n",
    "    \n",
    "    for top_n in [50, 100, 200]:\n",
    "        # Model recommendations\n",
    "        rec_model = get_recommendations_priority_model(camp_id, top_n)\n",
    "        if rec_model:\n",
    "            hits = len(set(rec_model) & set(actual_accepted))\n",
    "            results_model.append({'top_n': top_n, 'hits': hits, 'actual': len(actual_accepted)})\n",
    "        \n",
    "        # History baseline\n",
    "        rec_history = get_recommendations_history(camp_id, top_n)\n",
    "        if rec_history:\n",
    "            hits = len(set(rec_history) & set(actual_accepted))\n",
    "            results_history.append({'top_n': top_n, 'hits': hits, 'actual': len(actual_accepted)})\n",
    "\n",
    "# Summarize\n",
    "model_df = pd.DataFrame(results_model)\n",
    "history_df = pd.DataFrame(results_history)\n",
    "\n",
    "print(\"\\nPRIORITIZED LightGBM MODEL:\")\n",
    "for top_n in [50, 100, 200]:\n",
    "    sub = model_df[model_df['top_n'] == top_n]\n",
    "    recall = sub['hits'].sum() / sub['actual'].sum()\n",
    "    print(f\"  Top {top_n}: {recall*100:.1f}% recall ({sub['hits'].sum()} hits)\")\n",
    "\n",
    "print(\"\\nHISTORY BASELINE (recency_score only):\")\n",
    "for top_n in [50, 100, 200]:\n",
    "    sub = history_df[history_df['top_n'] == top_n]\n",
    "    recall = sub['hits'].sum() / sub['actual'].sum()\n",
    "    print(f\"  Top {top_n}: {recall*100:.1f}% recall ({sub['hits'].sum()} hits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL PRODUCTION FUNCTION - Uses best performing approach\n",
    "# Calculate full history for production (using ALL data, not just training)\n",
    "\n",
    "interactions['created_at'] = pd.to_datetime(interactions['created_at'])\n",
    "max_date = interactions['created_at'].max()\n",
    "interactions['days_ago'] = (max_date - interactions['created_at']).dt.days\n",
    "interactions['recency_weight'] = np.exp(-interactions['days_ago'] / 180)\n",
    "\n",
    "# Full history stats\n",
    "full_accepted = interactions[interactions['accepted'] == 1].copy()\n",
    "full_recency_scores = full_accepted.groupby('creator_id')['recency_weight'].sum().reset_index()\n",
    "full_recency_scores.columns = ['creator_id', 'recency_score']\n",
    "\n",
    "full_creator_history = interactions.groupby('creator_id').agg({\n",
    "    'accepted': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "full_creator_history.columns = ['creator_id', 'times_accepted', 'times_applied', 'acceptance_rate']\n",
    "full_creator_history = full_creator_history.merge(full_recency_scores, on='creator_id', how='left')\n",
    "full_creator_history['recency_score'] = full_creator_history['recency_score'].fillna(0)\n",
    "\n",
    "print(f\"Full history: {len(full_creator_history)} creators, {(full_creator_history['times_accepted'] > 0).sum()} with acceptances\")\n",
    "\n",
    "def recommend_influencers(campaign_id, top_n=100):\n",
    "    \"\"\"\n",
    "    Production-ready influencer recommendation.\n",
    "    \n",
    "    Process:\n",
    "    1. Apply group filters (tier, country, location, category, gender, age)\n",
    "    2. Filter by network (Instagram vs TikTok)\n",
    "    3. Rank by recency-weighted acceptance history\n",
    "    \n",
    "    Returns DataFrame with recommended influencers.\n",
    "    \"\"\"\n",
    "    camp = campaigns[campaigns['id'] == campaign_id].iloc[0]\n",
    "    network = camp['network_id']\n",
    "    network_name = 'Instagram' if network == 1 else 'TikTok' if network == 8 else 'Other'\n",
    "    \n",
    "    print(f\"Campaign: {camp['name']}\")\n",
    "    print(f\"Network: {network_name}\")\n",
    "    \n",
    "    # Step 1: Group filters\n",
    "    eligible = get_eligible_influencers(campaign_id)\n",
    "    print(f\"Eligible (after group filters): {len(eligible)}\")\n",
    "    \n",
    "    # Step 2: Network filter\n",
    "    pool = influencers_scored[\n",
    "        (influencers_scored['id'].isin(eligible)) &\n",
    "        (influencers_scored['network_id'] == network)\n",
    "    ].copy()\n",
    "    print(f\"On {network_name}: {len(pool)}\")\n",
    "    \n",
    "    if len(pool) == 0:\n",
    "        print(\"No eligible influencers!\")\n",
    "        return None\n",
    "    \n",
    "    # Exclude already contacted\n",
    "    already = interactions[interactions['campaign_id'] == campaign_id]['creator_id'].unique()\n",
    "    pool = pool[~pool['id'].isin(already)]\n",
    "    print(f\"After excluding contacted: {len(pool)}\")\n",
    "    \n",
    "    # Step 3: Add history and rank\n",
    "    pool = pool.merge(full_creator_history, left_on='id', right_on='creator_id', how='left')\n",
    "    pool['times_accepted'] = pool['times_accepted'].fillna(0)\n",
    "    pool['recency_score'] = pool['recency_score'].fillna(0)\n",
    "    pool['acceptance_rate'] = pool['acceptance_rate'].fillna(0)\n",
    "    \n",
    "    # Rank by recency-weighted acceptance\n",
    "    pool['score'] = pool['recency_score']\n",
    "    \n",
    "    # Return top N\n",
    "    result = pool.nlargest(top_n, 'score')[\n",
    "        ['id', 'account', 'name', 'followers', 'engagement', \n",
    "         'avg_likes', 'avg_comments', 'times_accepted', 'acceptance_rate', 'score']\n",
    "    ].copy()\n",
    "    \n",
    "    result = result.rename(columns={\n",
    "        'times_accepted': 'past_acceptances',\n",
    "        'acceptance_rate': 'historical_rate',\n",
    "        'score': 'recommendation_score'\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE: Top 20 recommendations for campaign 2993\")\n",
    "print(\"=\" * 70)\n",
    "recs = recommend_influencers(2993, top_n=20)\n",
    "if recs is not None:\n",
    "    print(recs.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
